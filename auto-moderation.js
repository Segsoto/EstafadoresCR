// Sistema de Moderaci√≥n Autom√°tica con Hugging Face
// 100% GRATUITO - Sin costos adicionales

class AutoModerationService {
    constructor() {
        // API gratuita de Hugging Face
        this.HF_API_URL = 'https://api-inference.huggingface.co/models';
        this.HF_TOKEN = process.env.HUGGING_FACE_TOKEN; // Opcional, funciona sin token pero con l√≠mites
    }

    // An√°lisis de sentimientos y detecci√≥n de contenido
    async moderateReport(report) {
        try {
            console.log(`ü§ñ Moderando reporte autom√°ticamente: ${report.name || 'sin nombre'}`);
            
            // Normalizar nombres de propiedades
            const phoneNumber = report.phone_number || report.phone;
            const description = report.description;
            const scamType = report.scam_type || report.company;
            
            // 1. Validaciones b√°sicas (instant√°neas)
            const basicCheck = this.basicValidation(phoneNumber, description);
            if (basicCheck.decision !== 'CONTINUE') {
                return basicCheck;
            }

            // 2. An√°lisis con IA de Hugging Face
            const aiAnalysis = await this.analyzeWithAI(description);
            
            // 3. Combinar resultados y tomar decisi√≥n
            const finalDecision = this.makeModerationDecision(basicCheck, aiAnalysis, report);
            
            console.log(`üéØ Decisi√≥n autom√°tica: ${finalDecision.status} (${finalDecision.confidence}% confianza)`);
            return finalDecision;
            
        } catch (error) {
            console.error('‚ùå Error en moderaci√≥n autom√°tica:', error);
            // Si falla la IA, enviar a moderaci√≥n manual por seguridad
            return {
                status: 'flagged',
                confidence: 0.5,
                reason: 'Error en an√°lisis autom√°tico - requiere revisi√≥n manual',
                requiresManualReview: true
            };
        }
    }

    // Validaciones b√°sicas sin IA
    basicValidation(phoneNumber, description) {
        const issues = [];
        
        // Validar n√∫mero de tel√©fono
        if (!phoneNumber || phoneNumber.length < 8) {
            issues.push('N√∫mero demasiado corto');
        }
        
        if (phoneNumber && !/^[0-9\-\s\+\(\)]{8,15}$/.test(phoneNumber)) {
            issues.push('Formato de n√∫mero inv√°lido');
        }
        
        // N√∫meros obviamente falsos
        const fakeNumbers = ['12345678', '00000000', '11111111', '99999999'];
        if (phoneNumber && fakeNumbers.includes(phoneNumber.replace(/[^0-9]/g, ''))) {
            issues.push('N√∫mero claramente falso');
        }
        
        // Validar descripci√≥n
        if (!description || description.trim().length < 10) {
            issues.push('Descripci√≥n demasiado corta');
        }
        
        if (description && description.length > 2000) {
            issues.push('Descripci√≥n demasiado larga');
        }
        
        // Detectar spam obvio
        if (description) {
            const spamPatterns = [
                /(.)\1{10,}/i, // Caracteres repetidos
                /^[A-Z\s!]{50,}$/i, // Solo may√∫sculas y exclamaciones
                /https?:\/\/[^\s]+/i, // URLs (sospechoso en reportes)
            ];
            
            for (const pattern of spamPatterns) {
                if (pattern.test(description)) {
                    issues.push('Posible spam detectado');
                    break;
                }
            }
        }
        
        // Decisi√≥n b√°sica
        if (issues.length === 0) {
            return { decision: 'CONTINUE', score: 0.8, issues: [] };
        } else if (issues.length >= 3) {
            return { 
                action: 'rejected', 
                confidence: 0.1, 
                reason: issues.join(', '),
                requiresManualReview: false
            };
        } else {
            return { 
                action: 'flagged', 
                confidence: 0.5, 
                reason: issues.join(', '),
                requiresManualReview: true
            };
        }
    }

    // An√°lisis con IA de Hugging Face (GRATIS)
    async analyzeWithAI(text) {
        try {
            // An√°lisis m√∫ltiple en paralelo
            const [sentimentResult, toxicityResult, spamResult] = await Promise.all([
                this.analyzeSentiment(text),
                this.analyzeToxicity(text),
                this.analyzeSpam(text)
            ]);

            return {
                sentiment: sentimentResult,
                toxicity: toxicityResult,
                spam: spamResult,
                overallScore: (sentimentResult.score + toxicityResult.score + spamResult.score) / 3
            };
        } catch (error) {
            console.error('Error en an√°lisis de IA:', error);
            return {
                sentiment: { score: 0.5, label: 'unknown' },
                toxicity: { score: 0.5, label: 'unknown' },
                spam: { score: 0.5, label: 'unknown' },
                overallScore: 0.5
            };
        }
    }

    // An√°lisis de sentimientos
    async analyzeSentiment(text) {
        try {
            const response = await fetch(`${this.HF_API_URL}/cardiffnlp/twitter-roberta-base-sentiment-latest`, {
                method: 'POST',
                headers: {
                    'Authorization': this.HF_TOKEN ? `Bearer ${this.HF_TOKEN}` : undefined,
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ inputs: text })
            });

            const result = await response.json();
            
            if (result && result[0]) {
                const topResult = result[0].reduce((prev, current) => 
                    (prev.score > current.score) ? prev : current
                );
                
                // Convertir a puntuaci√≥n √∫til para moderaci√≥n
                let score = 0.5;
                if (topResult.label === 'LABEL_0') score = 0.3; // Negativo
                if (topResult.label === 'LABEL_1') score = 0.5; // Neutral  
                if (topResult.label === 'LABEL_2') score = 0.7; // Positivo
                
                return { score, label: topResult.label, confidence: topResult.score };
            }
            
            return { score: 0.5, label: 'neutral', confidence: 0.5 };
        } catch (error) {
            console.error('Error en an√°lisis de sentimientos:', error);
            return { score: 0.5, label: 'error', confidence: 0 };
        }
    }

    // Detecci√≥n de toxicidad
    async analyzeToxicity(text) {
        try {
            const response = await fetch(`${this.HF_API_URL}/unitary/toxic-bert`, {
                method: 'POST',
                headers: {
                    'Authorization': this.HF_TOKEN ? `Bearer ${this.HF_TOKEN}` : undefined,
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ inputs: text })
            });

            const result = await response.json();
            
            if (result && result[0]) {
                const toxicScore = result[0].find(r => r.label === 'TOXIC')?.score || 0;
                return {
                    score: 1 - toxicScore, // Invertir: menos t√≥xico = mejor puntuaci√≥n
                    label: toxicScore > 0.7 ? 'toxic' : 'clean',
                    confidence: Math.abs(toxicScore - 0.5) * 2
                };
            }
            
            return { score: 0.5, label: 'unknown', confidence: 0 };
        } catch (error) {
            console.error('Error en an√°lisis de toxicidad:', error);
            return { score: 0.5, label: 'error', confidence: 0 };
        }
    }

    // Detecci√≥n de spam
    async analyzeSpam(text) {
        try {
            // Usar modelo de clasificaci√≥n general para detectar spam
            const response = await fetch(`${this.HF_API_URL}/huggingface/spam-detection`, {
                method: 'POST',
                headers: {
                    'Authorization': this.HF_TOKEN ? `Bearer ${this.HF_TOKEN}` : undefined,
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({ inputs: text })
            });

            const result = await response.json();
            
            if (result && result[0]) {
                const spamScore = result[0].find(r => r.label === 'SPAM')?.score || 0;
                return {
                    score: 1 - spamScore, // Invertir: menos spam = mejor puntuaci√≥n
                    label: spamScore > 0.6 ? 'spam' : 'ham',
                    confidence: Math.abs(spamScore - 0.5) * 2
                };
            }
            
            return { score: 0.5, label: 'unknown', confidence: 0 };
        } catch (error) {
            // Si no hay modelo de spam disponible, usar heur√≠sticas
            const spamIndicators = [
                /\b(gratis|free|click|premio|gana|dinero)\b/gi,
                /[!]{3,}/g,
                /[A-Z]{10,}/g
            ];
            
            const spamCount = spamIndicators.reduce((count, pattern) => {
                return count + (text.match(pattern) || []).length;
            }, 0);
            
            const spamScore = Math.min(spamCount * 0.2, 1);
            
            return {
                score: 1 - spamScore,
                label: spamScore > 0.5 ? 'spam' : 'ham',
                confidence: 0.6
            };
        }
    }

    // Decisi√≥n final de moderaci√≥n
    makeModerationDecision(basicCheck, aiAnalysis, report) {
        let finalScore = (basicCheck.score + aiAnalysis.overallScore) / 2;
        let reasons = [...(basicCheck.issues || [])];
        
        // Ajustar puntuaci√≥n basada en an√°lisis de IA
        if (aiAnalysis.toxicity.score < 0.3) {
            finalScore -= 0.2;
            reasons.push('Contenido potencialmente t√≥xico detectado');
        }
        
        if (aiAnalysis.spam.score < 0.4) {
            finalScore -= 0.15;
            reasons.push('Posible spam detectado por IA');
        }

        // Bonificaciones para reportes que parecen leg√≠timos
        if (report.scam_type && ['simpe', 'phishing', 'familiar'].includes(report.scam_type)) {
            finalScore += 0.1;
            reasons.push('Tipo de estafa com√∫n en Costa Rica');
        }

        // Decidir estado final
        let status, requiresManualReview = false;
        
        if (finalScore >= 0.75) {
            status = 'approved';
        } else if (finalScore <= 0.25) {
            status = 'rejected';
        } else {
            status = 'flagged';
            requiresManualReview = true;
        }

        return {
            action: status,  // Cambiar 'status' por 'action' para consistencia
            confidence: finalScore,  // Mantener como decimal (0.0 - 1.0)
            reason: reasons.join(', ') || 'An√°lisis autom√°tico completado',
            requiresManualReview,
            details: {
                sentiment: aiAnalysis.sentiment,
                toxicity: aiAnalysis.toxicity,
                spam: aiAnalysis.spam
            }
        };
    }
}

module.exports = AutoModerationService;
